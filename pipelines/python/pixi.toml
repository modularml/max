[project]
authors = [ "Modular <hello@modular.com>",]
channels = [ "conda-forge", "https://conda.modular.com/max/",]
description = "End-to-end execution of Llama3 using the Max Engine"
name = "Python Pipelines"
platforms = [ "osx-arm64", "linux-aarch64", "linux-64",]
version = "0.1.0"

[tasks]
llama3 = "python pipelines.py llama3"

[dependencies]
python = ">=3.9,<3.13"
max = ">=24.5.0a,<24.6"

[pypi-dependencies]
click = ">=8.1.7"
gguf = ">= 0.10.0"
sentencepiece = ">= 0.2.0"
requests = ">= 2.32.3"
tokenizers = ">= 0.19.1"
transformers = ">= 4.44.2"
